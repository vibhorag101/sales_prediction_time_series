{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 17:23:44.974177: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-02 17:23:45.032788: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-02 17:23:45.032843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-02 17:23:45.034422: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-02 17:23:45.044980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-02 17:23:46.042465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6463692, 5)\n"
     ]
    }
   ],
   "source": [
    "# load the train.csv file into a pandas dataframe\n",
    "df = pd.read_csv('TRAIN.csv')\n",
    "#convert the dates columns to a single column as \"Date \" with associated sales\n",
    "df = pd.melt(df, id_vars=['Item code', 'Category', 'State'], var_name='date', value_name='sales')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date from train set: 2017-01-29\n",
      "Max date from train set: 2022-02-22\n",
      "Date 90 days ago from start predict date: 2021-11-24\n"
     ]
    }
   ],
   "source": [
    "print('Min date from train set: %s' % df['date'].min().date())\n",
    "print('Max date from train set: %s' % df['date'].max().date())\n",
    "\n",
    "# date before 3 months from the last date in the train set\n",
    "date_90_days_ago = df['date'].max() - pd.DateOffset(days=90)\n",
    "print('Date 90 days ago from start predict date: %s' % date_90_days_ago.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date from chosen dataset: 2021-09-27\n",
      "(520308, 5)\n"
     ]
    }
   ],
   "source": [
    "# choose dataframe with date 150 days before the last date\n",
    "date_149_days_ago = df['date'].max() - pd.DateOffset(days=149)\n",
    "df = df[df['date'] > date_149_days_ago]\n",
    "print('Min date from chosen dataset: %s' % df['date'].min().date())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to training time series format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by date, item code, category and state and calculate the mean sales\n",
    "df = df.sort_values('date').groupby(['Item code','Category','State','date'], as_index=False)\n",
    "df = df.agg({'sales':['mean']})\n",
    "df.columns = ['Item code','Category','State','date','sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
    "    # cols stores the shifted dataframes\n",
    "    shifted_dataframes, shifted_column_names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(window, 0, -1):\n",
    "        # we are shifting the dataframe rows by i steps and are storing the new dataframes and there column names in a list\n",
    "        shifted_dataframes.append(data.shift(i))\n",
    "        shifted_column_names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
    "    # Current timestep (t=0)\n",
    "    shifted_dataframes.append(data)\n",
    "    shifted_column_names += [('%s(t)' % (col)) for col in data.columns]\n",
    "    # Target timestep (t=lag)\n",
    "    shifted_dataframes.append(data.shift(-lag))\n",
    "    shifted_column_names += [('%s(t+%d)' % (col, lag)) for col in data.columns]\n",
    "    # Put it all together\n",
    "    agg = pd.concat(shifted_dataframes, axis=1)\n",
    "    agg.columns = shifted_column_names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the timeseries data into lagged features data with target sales after 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520308, 305)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item code(t-59)</th>\n",
       "      <th>Category(t-59)</th>\n",
       "      <th>State(t-59)</th>\n",
       "      <th>date(t-59)</th>\n",
       "      <th>sales(t-59)</th>\n",
       "      <th>Item code(t-58)</th>\n",
       "      <th>Category(t-58)</th>\n",
       "      <th>State(t-58)</th>\n",
       "      <th>date(t-58)</th>\n",
       "      <th>sales(t-58)</th>\n",
       "      <th>...</th>\n",
       "      <th>Item code(t)</th>\n",
       "      <th>Category(t)</th>\n",
       "      <th>State(t)</th>\n",
       "      <th>date(t)</th>\n",
       "      <th>sales(t)</th>\n",
       "      <th>Item code(t+90)</th>\n",
       "      <th>Category(t+90)</th>\n",
       "      <th>State(t+90)</th>\n",
       "      <th>date(t+90)</th>\n",
       "      <th>sales(t+90)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANTIBIOTIC_001</td>\n",
       "      <td>ANTIBIOTIC</td>\n",
       "      <td>MH</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item code(t-59) Category(t-59) State(t-59) date(t-59)  sales(t-59)  \\\n",
       "0            None           None        None        NaT          NaN   \n",
       "1            None           None        None        NaT          NaN   \n",
       "2            None           None        None        NaT          NaN   \n",
       "3            None           None        None        NaT          NaN   \n",
       "4            None           None        None        NaT          NaN   \n",
       "\n",
       "  Item code(t-58) Category(t-58) State(t-58) date(t-58)  sales(t-58)  ...  \\\n",
       "0            None           None        None        NaT          NaN  ...   \n",
       "1            None           None        None        NaT          NaN  ...   \n",
       "2            None           None        None        NaT          NaN  ...   \n",
       "3            None           None        None        NaT          NaN  ...   \n",
       "4            None           None        None        NaT          NaN  ...   \n",
       "\n",
       "     Item code(t) Category(t) State(t)    date(t)  sales(t) Item code(t+90)  \\\n",
       "0  ANTIBIOTIC_001  ANTIBIOTIC       MH 2021-09-27       0.0  ANTIBIOTIC_001   \n",
       "1  ANTIBIOTIC_001  ANTIBIOTIC       MH 2021-09-28       0.0  ANTIBIOTIC_001   \n",
       "2  ANTIBIOTIC_001  ANTIBIOTIC       MH 2021-09-29       0.0  ANTIBIOTIC_001   \n",
       "3  ANTIBIOTIC_001  ANTIBIOTIC       MH 2021-09-30       0.0  ANTIBIOTIC_001   \n",
       "4  ANTIBIOTIC_001  ANTIBIOTIC       MH 2021-10-01       0.0  ANTIBIOTIC_001   \n",
       "\n",
       "  Category(t+90) State(t+90) date(t+90)  sales(t+90)  \n",
       "0     ANTIBIOTIC          MH 2021-12-26          1.0  \n",
       "1     ANTIBIOTIC          MH 2021-12-27          0.0  \n",
       "2     ANTIBIOTIC          MH 2021-12-28          0.0  \n",
       "3     ANTIBIOTIC          MH 2021-12-29          0.0  \n",
       "4     ANTIBIOTIC          MH 2021-12-30          0.0  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 59\n",
    "lag = 90\n",
    "series = series_to_supervised(df, window=window, lag=lag,dropnan=False)\n",
    "print(series.shape)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid the scenario  when we are trying to predict the sale of a different product using different product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314280, 305)\n"
     ]
    }
   ],
   "source": [
    "last_Item_code = 'Item code(t-%d)' % window\n",
    "last_category = 'Category(t-%d)' % window\n",
    "last_state = 'State(t-%d)' % window\n",
    "\n",
    "series = series[(series['Item code(t)'] == series[last_Item_code])]\n",
    "series = series[(series['Category(t)'] == series[last_category])]\n",
    "series = series[(series['State(t)'] == series[last_state])]\n",
    "\n",
    "print(series.shape)\n",
    "# series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date from train set: 2021-11-25\n",
      "Max date from train set: 2022-02-22\n",
      "2022-02-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print('Min date from train set: %s' % series['date(t)'].min().date())\n",
    "print('Max date from train set: %s' % series['date(t)'].max().date())\n",
    "\n",
    "print(series['date(t)'].min().date()+pd.DateOffset(days=lag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the extra Item code, Category and state columns as they are same across all 30 lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314280, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales(t-59)</th>\n",
       "      <th>sales(t-58)</th>\n",
       "      <th>sales(t-57)</th>\n",
       "      <th>sales(t-56)</th>\n",
       "      <th>sales(t-55)</th>\n",
       "      <th>sales(t-54)</th>\n",
       "      <th>sales(t-53)</th>\n",
       "      <th>sales(t-52)</th>\n",
       "      <th>sales(t-51)</th>\n",
       "      <th>sales(t-50)</th>\n",
       "      <th>...</th>\n",
       "      <th>sales(t-8)</th>\n",
       "      <th>sales(t-7)</th>\n",
       "      <th>sales(t-6)</th>\n",
       "      <th>sales(t-5)</th>\n",
       "      <th>sales(t-4)</th>\n",
       "      <th>sales(t-3)</th>\n",
       "      <th>sales(t-2)</th>\n",
       "      <th>sales(t-1)</th>\n",
       "      <th>sales(t)</th>\n",
       "      <th>sales(t+90)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sales(t-59)  sales(t-58)  sales(t-57)  sales(t-56)  sales(t-55)  \\\n",
       "59          0.0          0.0          0.0          0.0          0.0   \n",
       "60          0.0          0.0          0.0          0.0          0.0   \n",
       "61          0.0          0.0          0.0          0.0          0.0   \n",
       "62          0.0          0.0          0.0          0.0          4.0   \n",
       "63          0.0          0.0          0.0          4.0          0.0   \n",
       "\n",
       "    sales(t-54)  sales(t-53)  sales(t-52)  sales(t-51)  sales(t-50)  ...  \\\n",
       "59          0.0          0.0          4.0          0.0          1.0  ...   \n",
       "60          0.0          4.0          0.0          1.0          0.0  ...   \n",
       "61          4.0          0.0          1.0          0.0          0.0  ...   \n",
       "62          0.0          1.0          0.0          0.0          0.0  ...   \n",
       "63          1.0          0.0          0.0          0.0          1.0  ...   \n",
       "\n",
       "    sales(t-8)  sales(t-7)  sales(t-6)  sales(t-5)  sales(t-4)  sales(t-3)  \\\n",
       "59         1.0         6.0         0.0         0.0         1.0         1.0   \n",
       "60         6.0         0.0         0.0         1.0         1.0         1.0   \n",
       "61         0.0         0.0         1.0         1.0         1.0         1.0   \n",
       "62         0.0         1.0         1.0         1.0         1.0         0.0   \n",
       "63         1.0         1.0         1.0         1.0         0.0         2.0   \n",
       "\n",
       "    sales(t-2)  sales(t-1)  sales(t)  sales(t+90)  \n",
       "59         1.0         1.0       0.0          0.0  \n",
       "60         1.0         0.0       2.0          0.0  \n",
       "61         0.0         2.0       1.0          0.0  \n",
       "62         2.0         1.0       0.0          0.0  \n",
       "63         1.0         0.0       1.0          0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [('%s(t+%d)' % (col, lag)) for col in ['Item code', 'Category', 'State', 'date']]\n",
    "for i in range(window, 0, -1):\n",
    "    columns_to_drop += [('%s(t-%d)' % (col, i)) for col in ['Item code', 'Category', 'State','date']]\n",
    "series.drop(columns_to_drop, axis=1, inplace=True)\n",
    "series.drop(['Item code(t)', 'Category(t)', 'State(t)','date(t)'], axis=1, inplace=True)\n",
    "print(series.shape)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now apply normalization to the data\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled = scaler.fit_transform(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314280, 60)\n",
      "(314280,)\n"
     ]
    }
   ],
   "source": [
    "labels_col = 'sales(t+%d)' % lag\n",
    "labels = series[labels_col]\n",
    "series = series.drop(labels_col, axis=1)\n",
    "\n",
    "# convert the labels and the features to numpy arrays\n",
    "X = series.values\n",
    "y = labels.values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set shape (314280, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "print('Validation set shape', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 17:23:57.047580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22319 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:98:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch = 256\n",
    "lr = 0.0003\n",
    "adam = optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 17:23:57.415041: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(loss='mse', optimizer=adam)\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "from keras.models import load_model\n",
    "model_lstm = load_model('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9822/9822 [==============================] - 229s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = model_lstm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train.csv file into a pandas dataframe\n",
    "df = pd.read_csv('TRAIN.csv')\n",
    "#convert the dates columns to a single column as \"Date \" with associated sales\n",
    "df = pd.melt(df, id_vars=['Item code', 'Category', 'State'], var_name='date', value_name='sales')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 90 days ago from start predict date: 2021-11-24\n",
      "Min date from train set: 2021-11-25\n"
     ]
    }
   ],
   "source": [
    "date_90_days_ago_from_first_prediction = df['date'].max() - pd.DateOffset(days=90)\n",
    "print('Date 90 days ago from start predict date: %s' % date_90_days_ago_from_first_prediction.date())\n",
    "df= df[df['date'] > date_90_days_ago_from_first_prediction]\n",
    "print('Min date from train set: %s' % df['date'].min().date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date from train set: 2022-02-23\n"
     ]
    }
   ],
   "source": [
    "# offset each date by 90 days to get the real date\n",
    "df['date'] = df['date'] + pd.to_timedelta(90, unit='d')\n",
    "print('Min date from train set: %s' % df['date'].min().date())\n",
    "\n",
    "# now replace the sales column with the predicted values\n",
    "df['sales'] = lstm_pred\n",
    "\n",
    "# convert datetime to string with just the date\n",
    "df['date'] = df['date'].dt.strftime('%m-%d-%y')\n",
    "\n",
    "# now we need to convert the dataframe to the original format\n",
    "df = df.pivot_table(index=['Item code', 'Category', 'State'], columns='date', values='sales').reset_index()\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
